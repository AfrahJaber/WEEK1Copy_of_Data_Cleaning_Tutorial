{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K1F-oY4BI45P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "BzrLQRRGTdu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Titanic-Dataset.csv')"
      ],
      "metadata": {
        "id": "bc3UPU7AKzKG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Null Values"
      ],
      "metadata": {
        "id": "0OFnt7E-Tkgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values (1 line)\n",
        "df.isnull().sum()\n",
        "# Fill null values for 'Embarked' with the mode(1 line)\n",
        "df['Embarked']=df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
        "# Drop rows with null values in 'Cabin' (or alternatively, you can fill it with a placeholder) (1 line)\n",
        "df=df.dropna(subset=['Cabin'])\n"
      ],
      "metadata": {
        "id": "tCRLPInPK3ro"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Duplicates"
      ],
      "metadata": {
        "id": "ymFhv83FV80H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates (1 line)\n",
        "df.duplicated().sum()\n",
        "\n",
        "# Drop duplicates if any (1 line)\n",
        "\n",
        "df2=df.drop_duplicates()"
      ],
      "metadata": {
        "id": "HzmNbIDuLmEw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Outliers"
      ],
      "metadata": {
        "id": "RkPW85MbV_8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to remove outliers using the IQR method\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# Remove outliers from 'Fare' using the remove_outilers function (1 line)\n",
        "\n",
        "df = remove_outliers(df, 'Fare')"
      ],
      "metadata": {
        "id": "NsffaZ2DL06B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling and Normalization"
      ],
      "metadata": {
        "id": "kOTEDjprUiwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Standard scaling for 'Fare' (2 lines)\n",
        "scaler = StandardScaler() # نسوي استيراد\n",
        "df['Fare_scaked'] = scaler.fit_transform(df[['Fare']])\n",
        "\n",
        "# Min-Max scaling for 'Age' (2 lines)\n",
        "scaler = MinMaxScaler()\n",
        "df['Age_scaled'] = scaler.fit_transform(df[['Age']])\n"
      ],
      "metadata": {
        "id": "k3AaqNXcTaDR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding Categorical Variables"
      ],
      "metadata": {
        "id": "ETtUvmP3Uz1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for 'Embarked' and 'Sex' (1 line)\n",
        "df = pd.get_dummies(df, columns=['Embarked', 'Sex'])"
      ],
      "metadata": {
        "id": "OxjK9FbhU4oq"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}